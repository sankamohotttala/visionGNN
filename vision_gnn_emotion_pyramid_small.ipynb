{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "O98vdu8GtGuU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f930532-e833-4e35-86b5-14bdcfb590f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "obxxw6Yde1xB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e2fafe5-2f96-4da9-c07d-83f16b11848e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (0.9.7)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.2+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.17.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.3.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (16.0.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.23.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Requirement already satisfied: torchprofile in /usr/local/lib/python3.10/dist-packages (0.0.4)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.10/dist-packages (from torchprofile) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.10/dist-packages (from torchprofile) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision>=0.4 in /usr/local/lib/python3.10/dist-packages (from torchprofile) (0.15.2+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->torchprofile) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4->torchprofile) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4->torchprofile) (16.0.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.4->torchprofile) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.4->torchprofile) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4->torchprofile) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.4->torchprofile) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.4->torchprofile) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.4->torchprofile) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.4->torchprofile) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4->torchprofile) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install timm\n",
        "!pip install torchprofile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3h2d56JR0DB_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Pa52UtLfVLWc"
      },
      "outputs": [],
      "source": [
        "from timm.models import create_model\n",
        "from timm.models.registry import register_model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Sequential as Seq, Linear as Lin, Conv2d\n",
        "from timm.models.layers import DropPath\n",
        "import numpy as np\n",
        "from timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
        "from torchprofile import profile_macs\n",
        "from timm.optim import create_optimizer\n",
        "from types import SimpleNamespace\n",
        "from timm.scheduler import create_scheduler\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import math\n",
        "from torch.utils.data import Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from timm.utils import *\n",
        "torch.backends.cudnn.benchmark = True\n",
        "from collections import OrderedDict\n",
        "import os\n",
        "from timm.data.dataset import ImageDataset\n",
        "from datetime import date\n",
        "\n",
        "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VkiTPWoU3y1"
      },
      "source": [
        "#Model classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2Pu9tr-rpScw"
      },
      "outputs": [],
      "source": [
        "def get_1d_sincos_pos_embed_from_grid(embed_dim, pos):\n",
        "    \"\"\"\n",
        "    embed_dim: output dimension for each position\n",
        "    pos: a list of positions to be encoded: size (M,)\n",
        "    out: (M, D)\n",
        "    \"\"\"\n",
        "    assert embed_dim % 2 == 0\n",
        "    omega = np.arange(embed_dim // 2, dtype=np.float)\n",
        "    omega /= embed_dim / 2.\n",
        "    omega = 1. / 10000**omega  # (D/2,)\n",
        "\n",
        "    pos = pos.reshape(-1)  # (M,)\n",
        "    out = np.einsum('m,d->md', pos, omega)  # (M, D/2), outer product\n",
        "\n",
        "    emb_sin = np.sin(out) # (M, D/2)\n",
        "    emb_cos = np.cos(out) # (M, D/2)\n",
        "\n",
        "    emb = np.concatenate([emb_sin, emb_cos], axis=1)  # (M, D)\n",
        "    return emb\n",
        "\n",
        "def get_2d_sincos_pos_embed_from_grid(embed_dim, grid):\n",
        "    assert embed_dim % 2 == 0\n",
        "\n",
        "    # use half of dimensions to encode grid_h\n",
        "    emb_h = get_1d_sincos_pos_embed_from_grid(embed_dim // 2, grid[0])  # (H*W, D/2)\n",
        "    emb_w = get_1d_sincos_pos_embed_from_grid(embed_dim // 2, grid[1])  # (H*W, D/2)\n",
        "\n",
        "    emb = np.concatenate([emb_h, emb_w], axis=1) # (H*W, D)\n",
        "    return emb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Qtf-VWJkpOvn"
      },
      "outputs": [],
      "source": [
        "def get_2d_sincos_pos_embed(embed_dim, grid_size, cls_token=False):\n",
        "    \"\"\"\n",
        "    grid_size: int of the grid height and width\n",
        "    return:\n",
        "    pos_embed: [grid_size*grid_size, embed_dim] or [1+grid_size*grid_size, embed_dim] (w/ or w/o cls_token)\n",
        "    \"\"\"\n",
        "    grid_h = np.arange(grid_size, dtype=np.float32)\n",
        "    grid_w = np.arange(grid_size, dtype=np.float32)\n",
        "    grid = np.meshgrid(grid_w, grid_h)  # here w goes first\n",
        "    grid = np.stack(grid, axis=0)\n",
        "\n",
        "    grid = grid.reshape([2, 1, grid_size, grid_size])\n",
        "    pos_embed = get_2d_sincos_pos_embed_from_grid(embed_dim, grid)\n",
        "    if cls_token:\n",
        "        pos_embed = np.concatenate([np.zeros([1, embed_dim]), pos_embed], axis=0)\n",
        "    return pos_embed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iA8QnCxypKZu"
      },
      "outputs": [],
      "source": [
        "def get_2d_relative_pos_embed(embed_dim, grid_size):\n",
        "    \"\"\"\n",
        "    grid_size: int of the grid height and width\n",
        "    return:\n",
        "    pos_embed: [grid_size*grid_size, grid_size*grid_size]\n",
        "    \"\"\"\n",
        "    pos_embed = get_2d_sincos_pos_embed(embed_dim, grid_size)\n",
        "    relative_pos = 2 * np.matmul(pos_embed, pos_embed.transpose()) / pos_embed.shape[1]\n",
        "    return relative_pos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kCOKocLfp7HP"
      },
      "outputs": [],
      "source": [
        "def pairwise_distance(x):\n",
        "    \"\"\"\n",
        "    Compute pairwise distance of a point cloud.\n",
        "    Args:\n",
        "        x: tensor (batch_size, num_points, num_dims)\n",
        "    Returns:\n",
        "        pairwise distance: (batch_size, num_points, num_points)\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        x_inner = -2*torch.matmul(x, x.transpose(2, 1))\n",
        "        x_square = torch.sum(torch.mul(x, x), dim=-1, keepdim=True)\n",
        "        return x_square + x_inner + x_square.transpose(2, 1)\n",
        "\n",
        "\n",
        "def part_pairwise_distance(x, start_idx=0, end_idx=1):\n",
        "    \"\"\"\n",
        "    Compute pairwise distance of a point cloud.\n",
        "    Args:\n",
        "        x: tensor (batch_size, num_points, num_dims)\n",
        "    Returns:\n",
        "        pairwise distance: (batch_size, num_points, num_points)\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        x_part = x[:, start_idx:end_idx]\n",
        "        x_square_part = torch.sum(torch.mul(x_part, x_part), dim=-1, keepdim=True)\n",
        "        x_inner = -2*torch.matmul(x_part, x.transpose(2, 1))\n",
        "        x_square = torch.sum(torch.mul(x, x), dim=-1, keepdim=True)\n",
        "        return x_square_part + x_inner + x_square.transpose(2, 1)\n",
        "\n",
        "\n",
        "def xy_pairwise_distance(x, y):\n",
        "    \"\"\"\n",
        "    Compute pairwise distance of a point cloud.\n",
        "    Args:\n",
        "        x: tensor (batch_size, num_points, num_dims)\n",
        "    Returns:\n",
        "        pairwise distance: (batch_size, num_points, num_points)\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        xy_inner = -2*torch.matmul(x, y.transpose(2, 1))\n",
        "        x_square = torch.sum(torch.mul(x, x), dim=-1, keepdim=True)\n",
        "        y_square = torch.sum(torch.mul(y, y), dim=-1, keepdim=True)\n",
        "        return x_square + xy_inner + y_square.transpose(2, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yMvYADSapzyS"
      },
      "outputs": [],
      "source": [
        "def dense_knn_matrix(x, k=16, relative_pos=None):\n",
        "    \"\"\"Get KNN based on the pairwise distance.\n",
        "    Args:\n",
        "        x: (batch_size, num_dims, num_points, 1)\n",
        "        k: int\n",
        "    Returns:\n",
        "        nearest neighbors: (batch_size, num_points, k) (batch_size, num_points, k)\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        x = x.transpose(2, 1).squeeze(-1)\n",
        "        batch_size, n_points, n_dims = x.shape\n",
        "        ### memory efficient implementation ###\n",
        "        n_part = 10000\n",
        "        if n_points > n_part:\n",
        "            nn_idx_list = []\n",
        "            groups = math.ceil(n_points / n_part)\n",
        "            for i in range(groups):\n",
        "                start_idx = n_part * i\n",
        "                end_idx = min(n_points, n_part * (i + 1))\n",
        "                dist = part_pairwise_distance(x.detach(), start_idx, end_idx)\n",
        "                if relative_pos is not None:\n",
        "                    dist += relative_pos[:, start_idx:end_idx]\n",
        "                _, nn_idx_part = torch.topk(-dist, k=k)\n",
        "                nn_idx_list += [nn_idx_part]\n",
        "            nn_idx = torch.cat(nn_idx_list, dim=1)\n",
        "        else:\n",
        "            dist = pairwise_distance(x.detach())\n",
        "            if relative_pos is not None:\n",
        "                dist += relative_pos\n",
        "            _, nn_idx = torch.topk(-dist, k=k) # b, n, k\n",
        "        ######\n",
        "        center_idx = torch.arange(0, n_points, device=x.device).repeat(batch_size, k, 1).transpose(2, 1)\n",
        "    return torch.stack((nn_idx, center_idx), dim=0)\n",
        "\n",
        "\n",
        "def xy_dense_knn_matrix(x, y, k=16, relative_pos=None):\n",
        "    \"\"\"Get KNN based on the pairwise distance.\n",
        "    Args:\n",
        "        x: (batch_size, num_dims, num_points, 1)\n",
        "        k: int\n",
        "    Returns:\n",
        "        nearest neighbors: (batch_size, num_points, k) (batch_size, num_points, k)\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        x = x.transpose(2, 1).squeeze(-1)\n",
        "        y = y.transpose(2, 1).squeeze(-1)\n",
        "        batch_size, n_points, n_dims = x.shape\n",
        "        dist = xy_pairwise_distance(x.detach(), y.detach())\n",
        "        if relative_pos is not None:\n",
        "            dist += relative_pos\n",
        "        _, nn_idx = torch.topk(-dist, k=k)\n",
        "        center_idx = torch.arange(0, n_points, device=x.device).repeat(batch_size, k, 1).transpose(2, 1)\n",
        "    return torch.stack((nn_idx, center_idx), dim=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qBGD65SCrwN0"
      },
      "outputs": [],
      "source": [
        "def act_layer(act, inplace=False, neg_slope=0.2, n_prelu=1):\n",
        "    # activation layer\n",
        "\n",
        "    act = act.lower()\n",
        "    if act == 'relu':\n",
        "        layer = nn.ReLU(inplace)\n",
        "    elif act == 'leakyrelu':\n",
        "        layer = nn.LeakyReLU(neg_slope, inplace)\n",
        "    elif act == 'prelu':\n",
        "        layer = nn.PReLU(num_parameters=n_prelu, init=neg_slope)\n",
        "    elif act == 'gelu':\n",
        "        layer = nn.GELU()\n",
        "    elif act == 'hswish':\n",
        "        layer = nn.Hardswish(inplace)\n",
        "    else:\n",
        "        raise NotImplementedError('activation layer [%s] is not found' % act)\n",
        "    return layer\n",
        "\n",
        "\n",
        "def norm_layer(norm, nc):\n",
        "    # normalization layer 2d\n",
        "    norm = norm.lower()\n",
        "    if norm == 'batch':\n",
        "        layer = nn.BatchNorm2d(nc, affine=True)\n",
        "    elif norm == 'instance':\n",
        "        layer = nn.InstanceNorm2d(nc, affine=False)\n",
        "    else:\n",
        "        raise NotImplementedError('normalization layer [%s] is not found' % norm)\n",
        "    return layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UCeAdMxVprRJ"
      },
      "outputs": [],
      "source": [
        "class DenseDilated(nn.Module):\n",
        "    \"\"\"\n",
        "    Find dilated neighbor from neighbor list\n",
        "\n",
        "    edge_index: (2, batch_size, num_points, k)\n",
        "    \"\"\"\n",
        "    def __init__(self, k=9, dilation=1, stochastic=False, epsilon=0.0):\n",
        "        super(DenseDilated, self).__init__()\n",
        "        self.dilation = dilation\n",
        "        self.stochastic = stochastic\n",
        "        self.epsilon = epsilon\n",
        "        self.k = k\n",
        "\n",
        "    def forward(self, edge_index):\n",
        "        if self.stochastic:\n",
        "            if torch.rand(1) < self.epsilon and self.training:\n",
        "                num = self.k * self.dilation\n",
        "                randnum = torch.randperm(num)[:self.k]\n",
        "                edge_index = edge_index[:, :, :, randnum]\n",
        "            else:\n",
        "                edge_index = edge_index[:, :, :, ::self.dilation]\n",
        "        else:\n",
        "            edge_index = edge_index[:, :, :, ::self.dilation]\n",
        "        return edge_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yeSlJ4_SpEP7"
      },
      "outputs": [],
      "source": [
        "class DenseDilatedKnnGraph(nn.Module):\n",
        "    \"\"\"\n",
        "    Find the neighbors' indices based on dilated knn\n",
        "    \"\"\"\n",
        "    def __init__(self, k=9, dilation=1, stochastic=False, epsilon=0.0):\n",
        "        super(DenseDilatedKnnGraph, self).__init__()\n",
        "        self.dilation = dilation\n",
        "        self.stochastic = stochastic\n",
        "        self.epsilon = epsilon\n",
        "        self.k = k\n",
        "        self._dilated = DenseDilated(k, dilation, stochastic, epsilon)\n",
        "\n",
        "    def forward(self, x, y=None, relative_pos=None):\n",
        "        if y is not None:\n",
        "            #### normalize\n",
        "            x = F.normalize(x, p=2.0, dim=1)\n",
        "            y = F.normalize(y, p=2.0, dim=1)\n",
        "            ####\n",
        "            edge_index = xy_dense_knn_matrix(x, y, self.k * self.dilation, relative_pos)\n",
        "        else:\n",
        "            #### normalize\n",
        "            x = F.normalize(x, p=2.0, dim=1)\n",
        "            ####\n",
        "            edge_index = dense_knn_matrix(x, self.k * self.dilation, relative_pos)\n",
        "        return self._dilated(edge_index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "I6P18OTTotN-"
      },
      "outputs": [],
      "source": [
        "class BasicConv(Seq):\n",
        "    def __init__(self, channels, act='relu', norm=None, bias=True, drop=0.):\n",
        "        m = []\n",
        "        for i in range(1, len(channels)):\n",
        "            m.append(Conv2d(channels[i - 1], channels[i], 1, bias=bias, groups=4))\n",
        "            if norm is not None and norm.lower() != 'none':\n",
        "                m.append(norm_layer(norm, channels[-1]))\n",
        "            if act is not None and act.lower() != 'none':\n",
        "                m.append(act_layer(act))\n",
        "            if drop > 0:\n",
        "                m.append(nn.Dropout2d(drop))\n",
        "\n",
        "        super(BasicConv, self).__init__(*m)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.InstanceNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "kbNmhDGcowUR"
      },
      "outputs": [],
      "source": [
        "def batched_index_select(x, idx):\n",
        "    r\"\"\"fetches neighbors features from a given neighbor idx\n",
        "\n",
        "    Args:\n",
        "        x (Tensor): input feature Tensor\n",
        "                :math:`\\mathbf{X} \\in \\mathbb{R}^{B \\times C \\times N \\times 1}`.\n",
        "        idx (Tensor): edge_idx\n",
        "                :math:`\\mathbf{X} \\in \\mathbb{R}^{B \\times N \\times l}`.\n",
        "    Returns:\n",
        "        Tensor: output neighbors features\n",
        "            :math:`\\mathbf{X} \\in \\mathbb{R}^{B \\times C \\times N \\times k}`.\n",
        "    \"\"\"\n",
        "    batch_size, num_dims, num_vertices_reduced = x.shape[:3]\n",
        "    _, num_vertices, k = idx.shape\n",
        "    idx_base = torch.arange(0, batch_size, device=idx.device).view(-1, 1, 1) * num_vertices_reduced\n",
        "    idx = idx + idx_base\n",
        "    idx = idx.contiguous().view(-1)\n",
        "\n",
        "    x = x.transpose(2, 1)\n",
        "    feature = x.contiguous().view(batch_size * num_vertices_reduced, -1)[idx, :]\n",
        "    feature = feature.view(batch_size, num_vertices, k, num_dims).permute(0, 3, 1, 2).contiguous()\n",
        "    return feature\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Ld3Ke2D6oBDu"
      },
      "outputs": [],
      "source": [
        "class MRConv2d(nn.Module):\n",
        "    \"\"\"\n",
        "    Max-Relative Graph Convolution (Paper: https://arxiv.org/abs/1904.03751) for dense data type\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, act='relu', norm=None, bias=True):\n",
        "        super(MRConv2d, self).__init__()\n",
        "        self.nn = BasicConv([in_channels*2, out_channels], act, norm, bias)\n",
        "\n",
        "    def forward(self, x, edge_index, y=None):\n",
        "        x_i = batched_index_select(x, edge_index[1])\n",
        "        if y is not None:\n",
        "            x_j = batched_index_select(y, edge_index[0])\n",
        "        else:\n",
        "            x_j = batched_index_select(x, edge_index[0])\n",
        "        x_j, _ = torch.max(x_j - x_i, -1, keepdim=True)\n",
        "        b, c, n, _ = x.shape\n",
        "        x = torch.cat([x.unsqueeze(2), x_j.unsqueeze(2)], dim=2).reshape(b, 2 * c, n, _)\n",
        "        return self.nn(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "LLfpTVbKoD1y"
      },
      "outputs": [],
      "source": [
        "class EdgeConv2d(nn.Module):\n",
        "    \"\"\"\n",
        "    Edge convolution layer (with activation, batch normalization) for dense data type\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, act='relu', norm=None, bias=True):\n",
        "        super(EdgeConv2d, self).__init__()\n",
        "        self.nn = BasicConv([in_channels * 2, out_channels], act, norm, bias)\n",
        "\n",
        "    def forward(self, x, edge_index, y=None):\n",
        "        x_i = batched_index_select(x, edge_index[1])\n",
        "        if y is not None:\n",
        "            x_j = batched_index_select(y, edge_index[0])\n",
        "        else:\n",
        "            x_j = batched_index_select(x, edge_index[0])\n",
        "        max_value, _ = torch.max(self.nn(torch.cat([x_i, x_j - x_i], dim=1)), -1, keepdim=True)\n",
        "        return max_value\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "gdcp-5LSoPzK"
      },
      "outputs": [],
      "source": [
        "class GraphSAGE(nn.Module):\n",
        "    \"\"\"\n",
        "    GraphSAGE Graph Convolution (Paper: https://arxiv.org/abs/1706.02216) for dense data type\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, act='relu', norm=None, bias=True):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.nn1 = BasicConv([in_channels, in_channels], act, norm, bias)\n",
        "        self.nn2 = BasicConv([in_channels*2, out_channels], act, norm, bias)\n",
        "\n",
        "    def forward(self, x, edge_index, y=None):\n",
        "        if y is not None:\n",
        "            x_j = batched_index_select(y, edge_index[0])\n",
        "        else:\n",
        "            x_j = batched_index_select(x, edge_index[0])\n",
        "        x_j, _ = torch.max(self.nn1(x_j), -1, keepdim=True)\n",
        "        return self.nn2(torch.cat([x, x_j], dim=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ufSsFt5YoQVn"
      },
      "outputs": [],
      "source": [
        "class GINConv2d(nn.Module):\n",
        "    \"\"\"\n",
        "    GIN Graph Convolution (Paper: https://arxiv.org/abs/1810.00826) for dense data type\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, act='relu', norm=None, bias=True):\n",
        "        super(GINConv2d, self).__init__()\n",
        "        self.nn = BasicConv([in_channels, out_channels], act, norm, bias)\n",
        "        eps_init = 0.0\n",
        "        self.eps = nn.Parameter(torch.Tensor([eps_init]))\n",
        "\n",
        "    def forward(self, x, edge_index, y=None):\n",
        "        if y is not None:\n",
        "            x_j = batched_index_select(y, edge_index[0])\n",
        "        else:\n",
        "            x_j = batched_index_select(x, edge_index[0])\n",
        "        x_j = torch.sum(x_j, -1, keepdim=True)\n",
        "        return self.nn((1 + self.eps) * x + x_j)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "UT_191ZmnyCu"
      },
      "outputs": [],
      "source": [
        "class GraphConv2d(nn.Module):\n",
        "    \"\"\"\n",
        "    Static graph convolution layer\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, conv='edge', act='relu', norm=None, bias=True):\n",
        "        super(GraphConv2d, self).__init__()\n",
        "        if conv == 'edge':\n",
        "            self.gconv = EdgeConv2d(in_channels, out_channels, act, norm, bias)\n",
        "        elif conv == 'mr':\n",
        "            self.gconv = MRConv2d(in_channels, out_channels, act, norm, bias)\n",
        "        elif conv == 'sage':\n",
        "            self.gconv = GraphSAGE(in_channels, out_channels, act, norm, bias)\n",
        "        elif conv == 'gin':\n",
        "            self.gconv = GINConv2d(in_channels, out_channels, act, norm, bias)\n",
        "        else:\n",
        "            raise NotImplementedError('conv:{} is not supported'.format(conv))\n",
        "\n",
        "    def forward(self, x, edge_index, y=None):\n",
        "        return self.gconv(x, edge_index, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "HsSlr4hrnrYD"
      },
      "outputs": [],
      "source": [
        "class DyGraphConv2d(GraphConv2d):\n",
        "    \"\"\"\n",
        "    Dynamic graph convolution layer\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=9, dilation=1, conv='edge', act='relu',\n",
        "                 norm=None, bias=True, stochastic=False, epsilon=0.0, r=1):\n",
        "        super(DyGraphConv2d, self).__init__(in_channels, out_channels, conv, act, norm, bias)\n",
        "        self.k = kernel_size\n",
        "        self.d = dilation\n",
        "        self.r = r\n",
        "        self.dilated_knn_graph = DenseDilatedKnnGraph(kernel_size, dilation, stochastic, epsilon)\n",
        "\n",
        "    def forward(self, x, relative_pos=None):\n",
        "        B, C, H, W = x.shape\n",
        "        y = None\n",
        "        if self.r > 1:\n",
        "            y = F.avg_pool2d(x, self.r, self.r)\n",
        "            y = y.reshape(B, C, -1, 1).contiguous()\n",
        "        x = x.reshape(B, C, -1, 1).contiguous()\n",
        "        edge_index = self.dilated_knn_graph(x, y, relative_pos)\n",
        "        x = super(DyGraphConv2d, self).forward(x, edge_index, y)\n",
        "        return x.reshape(B, -1, H, W).contiguous()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "GFK9C9sob8XY"
      },
      "outputs": [],
      "source": [
        "class Grapher(nn.Module):\n",
        "    \"\"\"\n",
        "    Grapher module with graph convolution and fc layers\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, kernel_size=9, dilation=1, conv='edge', act='relu', norm=None,\n",
        "                 bias=True,  stochastic=False, epsilon=0.0, r=1, n=196, drop_path=0.0, relative_pos=False):\n",
        "        super(Grapher, self).__init__()\n",
        "        self.channels = in_channels\n",
        "        self.n = n\n",
        "        self.r = r\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, in_channels, 1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "        )\n",
        "        self.graph_conv = DyGraphConv2d(in_channels, in_channels * 2, kernel_size, dilation, conv,\n",
        "                              act, norm, bias, stochastic, epsilon, r)\n",
        "        self.fc2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels * 2, in_channels, 1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "        )\n",
        "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
        "        self.relative_pos = None\n",
        "        if relative_pos:\n",
        "            print('using relative_pos')\n",
        "            relative_pos_tensor = torch.from_numpy(np.float32(get_2d_relative_pos_embed(in_channels,\n",
        "                int(n**0.5)))).unsqueeze(0).unsqueeze(1)\n",
        "            relative_pos_tensor = F.interpolate(\n",
        "                    relative_pos_tensor, size=(n, n//(r*r)), mode='bicubic', align_corners=False)\n",
        "            self.relative_pos = nn.Parameter(-relative_pos_tensor.squeeze(1), requires_grad=False)\n",
        "\n",
        "    def _get_relative_pos(self, relative_pos, H, W):\n",
        "        if relative_pos is None or H * W == self.n:\n",
        "            return relative_pos\n",
        "        else:\n",
        "            N = H * W\n",
        "            N_reduced = N // (self.r * self.r)\n",
        "            return F.interpolate(relative_pos.unsqueeze(0), size=(N, N_reduced), mode=\"bicubic\").squeeze(0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _tmp = x\n",
        "        x = self.fc1(x)\n",
        "        B, C, H, W = x.shape\n",
        "        relative_pos = self._get_relative_pos(self.relative_pos, H, W)\n",
        "        x = self.graph_conv(x, relative_pos)\n",
        "        x = self.fc2(x)\n",
        "        x = self.drop_path(x) + _tmp\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "dwaSYTC_Mqin"
      },
      "outputs": [],
      "source": [
        "class Downsample(nn.Module):\n",
        "    \"\"\" Convolution-based downsample\n",
        "    \"\"\"\n",
        "    def __init__(self, in_dim=3, out_dim=768):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_dim, out_dim, 3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(out_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "D1aWjFWjspbs"
      },
      "outputs": [],
      "source": [
        "class FFN(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features=None, out_features=None, act='relu', drop_path=0.0):\n",
        "        super().__init__()\n",
        "        out_features = out_features or in_features\n",
        "        hidden_features = hidden_features or in_features\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Conv2d(in_features, hidden_features, 1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(hidden_features),\n",
        "        )\n",
        "        self.act = act_layer(act)\n",
        "        self.fc2 = nn.Sequential(\n",
        "            nn.Conv2d(hidden_features, out_features, 1, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(out_features),\n",
        "        )\n",
        "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        shortcut = x\n",
        "        x = self.fc1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.drop_path(x) + shortcut\n",
        "        return x#.reshape(B, C, N, 1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "oEaBsINPtIY_"
      },
      "outputs": [],
      "source": [
        "class Stem(nn.Module):\n",
        "    \"\"\" Image to Visual Embedding\n",
        "    Overlap: https://arxiv.org/pdf/2106.13797.pdf\n",
        "    \"\"\"\n",
        "    def __init__(self, img_size=224, in_dim=3, out_dim=768, act='relu'):\n",
        "        super().__init__()\n",
        "        self.convs = nn.Sequential(\n",
        "            nn.Conv2d(in_dim, out_dim//2, 3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(out_dim//2),\n",
        "            act_layer(act),\n",
        "            nn.Conv2d(out_dim//2, out_dim, 3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(out_dim),\n",
        "            act_layer(act),\n",
        "            nn.Conv2d(out_dim, out_dim, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(out_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "o-q4U5IEbmp_"
      },
      "outputs": [],
      "source": [
        "class DeepGCN(torch.nn.Module):\n",
        "    def __init__(self, opt):\n",
        "        super(DeepGCN, self).__init__()\n",
        "        print(opt)\n",
        "        k = opt.k\n",
        "        act = opt.act\n",
        "        norm = opt.norm\n",
        "        bias = opt.bias\n",
        "        epsilon = opt.epsilon\n",
        "        stochastic = opt.use_stochastic\n",
        "        conv = opt.conv\n",
        "        emb_dims = opt.emb_dims\n",
        "        drop_path = opt.drop_path\n",
        "\n",
        "        blocks = opt.blocks\n",
        "        self.n_blocks = sum(blocks)\n",
        "        channels = opt.channels\n",
        "        reduce_ratios = [4, 2, 1, 1]\n",
        "        dpr = [x.item() for x in torch.linspace(0, drop_path, self.n_blocks)]  # stochastic depth decay rule\n",
        "        num_knn = [int(x.item()) for x in torch.linspace(k, k, self.n_blocks)]  # number of knn's k\n",
        "        max_dilation = 49 // max(num_knn)\n",
        "\n",
        "        self.stem = Stem(out_dim=channels[0], act=act)\n",
        "        self.pos_embed = nn.Parameter(torch.zeros(1, channels[0], 224//4, 224//4))\n",
        "        HW = 224 // 4 * 224 // 4\n",
        "\n",
        "        self.backbone = nn.ModuleList([])\n",
        "        idx = 0\n",
        "        for i in range(len(blocks)):\n",
        "            if i > 0:\n",
        "                self.backbone.append(Downsample(channels[i-1], channels[i]))\n",
        "                HW = HW // 4\n",
        "            for j in range(blocks[i]):\n",
        "                self.backbone += [\n",
        "                    Seq(Grapher(channels[i], num_knn[idx], min(idx // 4 + 1, max_dilation), conv, act, norm,\n",
        "                                    bias, stochastic, epsilon, reduce_ratios[i], n=HW, drop_path=dpr[idx],\n",
        "                                    relative_pos=True),\n",
        "                          FFN(channels[i], channels[i] * 4, act=act, drop_path=dpr[idx])\n",
        "                         )]\n",
        "                idx += 1\n",
        "        self.backbone = Seq(*self.backbone)\n",
        "\n",
        "        self.prediction = Seq(nn.Conv2d(channels[-1], 1024, 1, bias=True),\n",
        "                              nn.BatchNorm2d(1024),\n",
        "                              act_layer(act),\n",
        "                              nn.Dropout(opt.dropout),\n",
        "                              # nn.Conv2d(1024, 512, 1, bias=True),\n",
        "                              # nn.BatchNorm2d(512),\n",
        "                              # act_layer(act),\n",
        "                              # nn.Dropout(opt.dropout),\n",
        "                              # nn.Conv2d(512, 256, 1, bias=True),\n",
        "                              # nn.BatchNorm2d(256),\n",
        "                              # act_layer(act),\n",
        "                              # nn.Dropout(opt.dropout),\n",
        "                              nn.Conv2d(1024, opt.n_classes, 1, bias=True))\n",
        "        self.model_init()\n",
        "\n",
        "    def model_init(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, torch.nn.Conv2d):\n",
        "                torch.nn.init.kaiming_normal_(m.weight)\n",
        "                m.weight.requires_grad = True\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "                    m.bias.requires_grad = True\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.stem(inputs) + self.pos_embed\n",
        "        B, C, H, W = x.shape\n",
        "        for i in range(len(self.backbone)):\n",
        "            x = self.backbone[i](x)\n",
        "\n",
        "        x = F.adaptive_avg_pool2d(x, 1)\n",
        "        return self.prediction(x).squeeze(-1).squeeze(-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CsBFwOcVA3P"
      },
      "source": [
        "#MOdel Define"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "2IyrJda2bXZY"
      },
      "outputs": [],
      "source": [
        "def _cfg(url='', **kwargs):\n",
        "    return {\n",
        "        'url': url,\n",
        "        'num_classes': 7, 'input_size': (3, 224, 224), 'pool_size': None,\n",
        "        'crop_pct': .9, 'interpolation': 'bicubic',\n",
        "        'mean': IMAGENET_DEFAULT_MEAN, 'std': IMAGENET_DEFAULT_STD,\n",
        "        'first_conv': 'patch_embed.proj', 'classifier': 'head',\n",
        "        **kwargs\n",
        "    }\n",
        "\n",
        "default_cfgs = {\n",
        "    'vig_224_gelu': _cfg(\n",
        "        mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5),\n",
        "    ),\n",
        "    'vig_b_224_gelu': _cfg(\n",
        "        crop_pct=0.95, mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5),\n",
        "    ),\n",
        "}\n",
        "\n",
        "\n",
        "@register_model\n",
        "def pvig_s_224_gelu(pretrained=False, **kwargs):\n",
        "    class OptInit:\n",
        "        def __init__(self, num_classes=7, drop_path_rate=0.0, **kwargs):\n",
        "            self.k = 9 # neighbor num (default:9)\n",
        "            self.conv = 'mr' # graph conv layer {edge, mr}\n",
        "            self.act = 'gelu' # activation layer {relu, prelu, leakyrelu, gelu, hswish}\n",
        "            self.norm = 'batch' # batch or instance normalization {batch, instance}\n",
        "            self.bias = True # bias of conv layer True or False\n",
        "            self.dropout = 0.0 # dropout rate\n",
        "            self.use_dilation = True # use dilated knn or not\n",
        "            self.epsilon = 0.2 # stochastic epsilon for gcn\n",
        "            self.use_stochastic = False # stochastic for gcn, True or False\n",
        "            self.drop_path = drop_path_rate\n",
        "            self.blocks = [2,2,6,2] # number of basic blocks in the backbone\n",
        "            self.channels = [80, 160, 400, 640] # number of channels of deep features\n",
        "            self.n_classes = num_classes # Dimension of out_channels\n",
        "            self.emb_dims = 1024 # Dimension of embeddings\n",
        "\n",
        "    opt = OptInit(**kwargs)\n",
        "    model = DeepGCN(opt)\n",
        "    model.default_cfg = default_cfgs['vig_224_gelu']\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "A4Pul9mi9bw9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3448bf1d-7c59-441e-a816-7d7bd91b67f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7c952aed5670>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "torch.manual_seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "DA9BaG7wYFqI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f99a5514-9205-4391-f79e-df9475ee72d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 17] File exists: '/content/drive/MyDrive/emotion/2023-09-13'\n"
          ]
        }
      ],
      "source": [
        "folder_path  = '/content/drive/MyDrive/emotion/'\n",
        "date = date.today()\n",
        "results_main_path = os.path.join(folder_path,'{}'.format(date))\n",
        "\n",
        "try:\n",
        "    os.mkdir(results_main_path)\n",
        "    print('[Success] Created folder in results_main_path')\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "WORWiyqBVHh4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2d08e06-2c99-4c57-ce3b-fe10d6593456"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<__main__.pvig_s_224_gelu.<locals>.OptInit object at 0x7c946818b8b0>\n",
            "using relative_pos\n",
            "using relative_pos\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-243f8f51e5ff>:8: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  omega = np.arange(embed_dim // 2, dtype=np.float)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using relative_pos\n",
            "using relative_pos\n",
            "using relative_pos\n",
            "using relative_pos\n",
            "using relative_pos\n",
            "using relative_pos\n",
            "using relative_pos\n",
            "using relative_pos\n",
            "using relative_pos\n",
            "using relative_pos\n"
          ]
        }
      ],
      "source": [
        "model = create_model(\n",
        "        'pvig_s_224_gelu',\n",
        "        pretrained=False,\n",
        "        num_classes=7,\n",
        "        drop_rate=0.0,\n",
        "        drop_connect_rate=None,  # DEPRECATED, use drop_path\n",
        "        drop_path_rate=None,\n",
        "        drop_block_rate=None,\n",
        "        global_pool=None,\n",
        "        bn_tf=None,\n",
        "        bn_momentum=0.9,\n",
        "        bn_eps=None,\n",
        "        checkpoint_path='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "lXHV4YvBaJHo"
      },
      "outputs": [],
      "source": [
        "input_size = [1, 3, 224, 224]\n",
        "input = torch.randn(input_size)#.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "XfScQhjs0Kjx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "655dcfdb-a1ab-4def-94f8-881d4f54639f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeepGCN(\n",
              "  (stem): Stem(\n",
              "    (convs): Sequential(\n",
              "      (0): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): GELU(approximate='none')\n",
              "      (3): Conv2d(40, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (4): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): GELU(approximate='none')\n",
              "      (6): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (7): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (backbone): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Grapher(\n",
              "        (fc1): Sequential(\n",
              "          (0): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (graph_conv): DyGraphConv2d(\n",
              "          (gconv): MRConv2d(\n",
              "            (nn): BasicConv(\n",
              "              (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
              "              (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): GELU(approximate='none')\n",
              "            )\n",
              "          )\n",
              "          (dilated_knn_graph): DenseDilatedKnnGraph(\n",
              "            (_dilated): DenseDilated()\n",
              "          )\n",
              "        )\n",
              "        (fc2): Sequential(\n",
              "          (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "      (1): FFN(\n",
              "        (fc1): Sequential(\n",
              "          (0): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (act): GELU(approximate='none')\n",
              "        (fc2): Sequential(\n",
              "          (0): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Grapher(\n",
              "        (fc1): Sequential(\n",
              "          (0): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (graph_conv): DyGraphConv2d(\n",
              "          (gconv): MRConv2d(\n",
              "            (nn): BasicConv(\n",
              "              (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
              "              (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): GELU(approximate='none')\n",
              "            )\n",
              "          )\n",
              "          (dilated_knn_graph): DenseDilatedKnnGraph(\n",
              "            (_dilated): DenseDilated()\n",
              "          )\n",
              "        )\n",
              "        (fc2): Sequential(\n",
              "          (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "      (1): FFN(\n",
              "        (fc1): Sequential(\n",
              "          (0): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (act): GELU(approximate='none')\n",
              "        (fc2): Sequential(\n",
              "          (0): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "    )\n",
              "    (2): Downsample(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2d(80, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): Grapher(\n",
              "        (fc1): Sequential(\n",
              "          (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (graph_conv): DyGraphConv2d(\n",
              "          (gconv): MRConv2d(\n",
              "            (nn): BasicConv(\n",
              "              (0): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
              "              (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): GELU(approximate='none')\n",
              "            )\n",
              "          )\n",
              "          (dilated_knn_graph): DenseDilatedKnnGraph(\n",
              "            (_dilated): DenseDilated()\n",
              "          )\n",
              "        )\n",
              "        (fc2): Sequential(\n",
              "          (0): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "      (1): FFN(\n",
              "        (fc1): Sequential(\n",
              "          (0): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (act): GELU(approximate='none')\n",
              "        (fc2): Sequential(\n",
              "          (0): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (0): Grapher(\n",
              "        (fc1): Sequential(\n",
              "          (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (graph_conv): DyGraphConv2d(\n",
              "          (gconv): MRConv2d(\n",
              "            (nn): BasicConv(\n",
              "              (0): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
              "              (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): GELU(approximate='none')\n",
              "            )\n",
              "          )\n",
              "          (dilated_knn_graph): DenseDilatedKnnGraph(\n",
              "            (_dilated): DenseDilated()\n",
              "          )\n",
              "        )\n",
              "        (fc2): Sequential(\n",
              "          (0): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "      (1): FFN(\n",
              "        (fc1): Sequential(\n",
              "          (0): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (act): GELU(approximate='none')\n",
              "        (fc2): Sequential(\n",
              "          (0): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "    )\n",
              "    (5): Downsample(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2d(160, 400, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "        (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): Grapher(\n",
              "        (fc1): Sequential(\n",
              "          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (graph_conv): DyGraphConv2d(\n",
              "          (gconv): MRConv2d(\n",
              "            (nn): BasicConv(\n",
              "              (0): Conv2d(800, 800, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
              "              (1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): GELU(approximate='none')\n",
              "            )\n",
              "          )\n",
              "          (dilated_knn_graph): DenseDilatedKnnGraph(\n",
              "            (_dilated): DenseDilated()\n",
              "          )\n",
              "        )\n",
              "        (fc2): Sequential(\n",
              "          (0): Conv2d(800, 400, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "      (1): FFN(\n",
              "        (fc1): Sequential(\n",
              "          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (act): GELU(approximate='none')\n",
              "        (fc2): Sequential(\n",
              "          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): Grapher(\n",
              "        (fc1): Sequential(\n",
              "          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (graph_conv): DyGraphConv2d(\n",
              "          (gconv): MRConv2d(\n",
              "            (nn): BasicConv(\n",
              "              (0): Conv2d(800, 800, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
              "              (1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): GELU(approximate='none')\n",
              "            )\n",
              "          )\n",
              "          (dilated_knn_graph): DenseDilatedKnnGraph(\n",
              "            (_dilated): DenseDilated()\n",
              "          )\n",
              "        )\n",
              "        (fc2): Sequential(\n",
              "          (0): Conv2d(800, 400, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "      (1): FFN(\n",
              "        (fc1): Sequential(\n",
              "          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (act): GELU(approximate='none')\n",
              "        (fc2): Sequential(\n",
              "          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "    )\n",
              "    (8): Sequential(\n",
              "      (0): Grapher(\n",
              "        (fc1): Sequential(\n",
              "          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (graph_conv): DyGraphConv2d(\n",
              "          (gconv): MRConv2d(\n",
              "            (nn): BasicConv(\n",
              "              (0): Conv2d(800, 800, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
              "              (1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): GELU(approximate='none')\n",
              "            )\n",
              "          )\n",
              "          (dilated_knn_graph): DenseDilatedKnnGraph(\n",
              "            (_dilated): DenseDilated()\n",
              "          )\n",
              "        )\n",
              "        (fc2): Sequential(\n",
              "          (0): Conv2d(800, 400, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "      (1): FFN(\n",
              "        (fc1): Sequential(\n",
              "          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (act): GELU(approximate='none')\n",
              "        (fc2): Sequential(\n",
              "          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "    )\n",
              "    (9): Sequential(\n",
              "      (0): Grapher(\n",
              "        (fc1): Sequential(\n",
              "          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (graph_conv): DyGraphConv2d(\n",
              "          (gconv): MRConv2d(\n",
              "            (nn): BasicConv(\n",
              "              (0): Conv2d(800, 800, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
              "              (1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): GELU(approximate='none')\n",
              "            )\n",
              "          )\n",
              "          (dilated_knn_graph): DenseDilatedKnnGraph(\n",
              "            (_dilated): DenseDilated()\n",
              "          )\n",
              "        )\n",
              "        (fc2): Sequential(\n",
              "          (0): Conv2d(800, 400, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "      (1): FFN(\n",
              "        (fc1): Sequential(\n",
              "          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (act): GELU(approximate='none')\n",
              "        (fc2): Sequential(\n",
              "          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "    )\n",
              "    (10): Sequential(\n",
              "      (0): Grapher(\n",
              "        (fc1): Sequential(\n",
              "          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (graph_conv): DyGraphConv2d(\n",
              "          (gconv): MRConv2d(\n",
              "            (nn): BasicConv(\n",
              "              (0): Conv2d(800, 800, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
              "              (1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): GELU(approximate='none')\n",
              "            )\n",
              "          )\n",
              "          (dilated_knn_graph): DenseDilatedKnnGraph(\n",
              "            (_dilated): DenseDilated()\n",
              "          )\n",
              "        )\n",
              "        (fc2): Sequential(\n",
              "          (0): Conv2d(800, 400, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "      (1): FFN(\n",
              "        (fc1): Sequential(\n",
              "          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (act): GELU(approximate='none')\n",
              "        (fc2): Sequential(\n",
              "          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "    )\n",
              "    (11): Sequential(\n",
              "      (0): Grapher(\n",
              "        (fc1): Sequential(\n",
              "          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (graph_conv): DyGraphConv2d(\n",
              "          (gconv): MRConv2d(\n",
              "            (nn): BasicConv(\n",
              "              (0): Conv2d(800, 800, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
              "              (1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): GELU(approximate='none')\n",
              "            )\n",
              "          )\n",
              "          (dilated_knn_graph): DenseDilatedKnnGraph(\n",
              "            (_dilated): DenseDilated()\n",
              "          )\n",
              "        )\n",
              "        (fc2): Sequential(\n",
              "          (0): Conv2d(800, 400, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "      (1): FFN(\n",
              "        (fc1): Sequential(\n",
              "          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (act): GELU(approximate='none')\n",
              "        (fc2): Sequential(\n",
              "          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "    )\n",
              "    (12): Downsample(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2d(400, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "        (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (13): Sequential(\n",
              "      (0): Grapher(\n",
              "        (fc1): Sequential(\n",
              "          (0): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (graph_conv): DyGraphConv2d(\n",
              "          (gconv): MRConv2d(\n",
              "            (nn): BasicConv(\n",
              "              (0): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
              "              (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): GELU(approximate='none')\n",
              "            )\n",
              "          )\n",
              "          (dilated_knn_graph): DenseDilatedKnnGraph(\n",
              "            (_dilated): DenseDilated()\n",
              "          )\n",
              "        )\n",
              "        (fc2): Sequential(\n",
              "          (0): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "      (1): FFN(\n",
              "        (fc1): Sequential(\n",
              "          (0): Conv2d(640, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(2560, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (act): GELU(approximate='none')\n",
              "        (fc2): Sequential(\n",
              "          (0): Conv2d(2560, 640, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "    )\n",
              "    (14): Sequential(\n",
              "      (0): Grapher(\n",
              "        (fc1): Sequential(\n",
              "          (0): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (graph_conv): DyGraphConv2d(\n",
              "          (gconv): MRConv2d(\n",
              "            (nn): BasicConv(\n",
              "              (0): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
              "              (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): GELU(approximate='none')\n",
              "            )\n",
              "          )\n",
              "          (dilated_knn_graph): DenseDilatedKnnGraph(\n",
              "            (_dilated): DenseDilated()\n",
              "          )\n",
              "        )\n",
              "        (fc2): Sequential(\n",
              "          (0): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "      (1): FFN(\n",
              "        (fc1): Sequential(\n",
              "          (0): Conv2d(640, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(2560, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (act): GELU(approximate='none')\n",
              "        (fc2): Sequential(\n",
              "          (0): Conv2d(2560, 640, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (prediction): Sequential(\n",
              "    (0): Conv2d(640, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): GELU(approximate='none')\n",
              "    (3): Dropout(p=0.0, inplace=False)\n",
              "    (4): Conv2d(1024, 7, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "model.eval()\n",
        "#macs = profile_macs(model, input)\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "RHweVn7G0s-0"
      },
      "outputs": [],
      "source": [
        "args = SimpleNamespace()\n",
        "args.weight_decay = 0.05\n",
        "args.lr = 2e-3\n",
        "args.opt = 'adamw' #'lookahead_adam' to use `lookahead`\n",
        "args.momentum = 0.9\n",
        "args.sched='cosine'\n",
        "args.epochs=100\n",
        "args.min_lr=1e-5\n",
        "args.warmup_lr=1e-2\n",
        "args.warmup_epochs=5\n",
        "args.cooldown_epochs=3\n",
        "args.drop_path=0.1\n",
        "args.b=32\n",
        "args.output=''\n",
        "args.opt_eps=1e-8 #epsilon vlaue fo optimizer\n",
        "args.mixup=0.8\n",
        "args.cutmix=1.0\n",
        "args.model_ema=True\n",
        "args.model_ema_decay=0.99996\n",
        "args.aa='rand-m9-mstd0.5-inc1'  #Use AutoAugment policy\n",
        "args.color_jitter=0.4 #Color jitter factor\n",
        "args.repeated_aug=True\n",
        "args.remode='pixel' #Random erase mode\n",
        "args.reprob=0.25  #Random erase prob\n",
        "args.amp=False #NVIDIA Pex\n",
        "args.eval_metric='top1'\n",
        "args.local_rank=0\n",
        "args.model='vig_s_224_gelu'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "0DtBXFFS4EwF"
      },
      "outputs": [],
      "source": [
        "optimizer = create_optimizer(args, model)\n",
        "lr_scheduler, num_epochs = create_scheduler(args, optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JoR7_q0VFT1"
      },
      "source": [
        "#data loading and training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "KvmBBmDNLOyf"
      },
      "outputs": [],
      "source": [
        "data_path  = '/content/drive/MyDrive/emotion/'\n",
        "data_set_path='/content/drive/MyDrive/emotion/kdef_dataset'\n",
        "# train_path=os.path.join(data_path,'phishIRIS/train')\n",
        "# test_path=os.path.join(data_path,'phishIRIS/val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "5Hy8zgE7mBdM"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# transform=transforms.Compose([transforms.ToTensor(),transforms.Resize(size=(224,224),antialias=True)])\n",
        "\n",
        "# trainSet=torchvision.datasets.ImageFolder(root=data_path, split='train' transform=transform)\n",
        "# trainLoader=torch.utils.data.DataLoader(trainSet, batch_size=batch_size,shuffle=True,num_workers=2)\n",
        "\n",
        "# testSet=torchvision.datasets.STL10(root='./data', split='test', download=True, transform=transform)\n",
        "\n",
        "# testLoader=torch.utils.data.DataLoader(testSet, batch_size=batch_size,shuffle=True,num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "_eD2UB5TUASl"
      },
      "outputs": [],
      "source": [
        "def train_val_dataset(dataset, val_split=0.25):\n",
        "    train_idx, val_idx = train_test_split(list(range(len(dataset))), test_size=val_split)\n",
        "    datasets = {}\n",
        "    datasets['train'] = Subset(dataset, train_idx)\n",
        "    datasets['val'] = Subset(dataset, val_idx)\n",
        "    return datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "80fW0P0RrR91"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# batch_size=args.b\n",
        "# # trainSet=ImageDataset(train_path)\n",
        "# # testset=ImageDataset(test_path)\n",
        "# transform=transforms.Compose([transforms.ToTensor(),transforms.Resize(size=(224,224),antialias=True),transforms.RandomHorizontalFlip(p=0.5),transforms.RandomVerticalFlip(p=0.6)])\n",
        "\n",
        "# trainSet=torchvision.datasets.ImageFolder(root=train_path,  transform=transform)\n",
        "# testSet=torchvision.datasets.ImageFolder(root=test_path, transform=transform)\n",
        "\n",
        "# trainLoader=torch.utils.data.DataLoader(trainSet, batch_size=batch_size,shuffle=True,num_workers=1)\n",
        "# testLoader=torch.utils.data.DataLoader(testSet, batch_size=batch_size,shuffle=True,num_workers=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "W81SMdkMbySb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44ad858b-47ee-4c6c-ec22-e888712b357a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3588\n",
            "2691\n",
            "897\n",
            "Dataset ImageFolder\n",
            "    Number of datapoints: 3588\n",
            "    Root location: /content/drive/MyDrive/emotion/kdef_dataset\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
            "           )\n",
            "torch.Size([32, 3, 224, 224]) torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "batch_size=args.b\n",
        "# trainSet=ImageDataset(train_path)\n",
        "# testset=ImageDataset(test_path)\n",
        "transform=transforms.Compose([transforms.ToTensor(),transforms.Resize(size=(224,224),antialias=True)])\n",
        "\n",
        "dataSet=torchvision.datasets.ImageFolder(root=data_set_path,  transform=transform)\n",
        "\n",
        "print(len(dataSet))\n",
        "dataSets = train_val_dataset(dataSet)\n",
        "print(len(dataSets['train']))\n",
        "print(len(dataSets['val']))\n",
        "# The original dataset is available in the Subset class\n",
        "print(dataSets['train'].dataset)\n",
        "\n",
        "dataloaders = {x:torch.utils.data.DataLoader(dataSets[x],batch_size, shuffle=True, num_workers=4) for x in ['train','val']}\n",
        "x,y = next(iter(dataloaders['train']))\n",
        "print(x.shape, y.shape)\n",
        "#dataLoader=torch.utils.data.DataLoader(dataSet, batch_size=batch_size,shuffle=True,num_workers=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "BD7LhAZ3eHyy"
      },
      "outputs": [],
      "source": [
        "trainLoader=dataloaders['train']\n",
        "testLoader=dataloaders['val']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "41nGS6H85TaB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82f57eb0-edc2-4e3d-b3a7-de102334253b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2691\n",
            "897\n"
          ]
        }
      ],
      "source": [
        "print(len(trainLoader.dataset))\n",
        "print(len(testLoader.dataset))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "QBEwr5vgW5lZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6469d0f-8e5f-4bde-fda2-7ae01d2955eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([32, 3, 224, 224])\n",
            "Labels batch shape: torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "train_features, train_labels = next(iter(trainLoader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "ntOocCumYKEg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7be8d2e-8327-44fe-ae64-62c757cf9f28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'AF': 0, 'AN': 1, 'DI': 2, 'HA': 3, 'NE': 4, 'SA': 5, 'SU': 6}\n"
          ]
        }
      ],
      "source": [
        "print(dataSet.class_to_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "pj-dnEXCYKgJ"
      },
      "outputs": [],
      "source": [
        "#print(testSet.class_to_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "clHHvyaZTNZl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38f76e9f-2c61-41f6-ca82-c47896b37d11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla T4\n"
          ]
        }
      ],
      "source": [
        "if(torch.cuda.is_available()):\n",
        "  print(torch.cuda.get_device_name(0))\n",
        "  model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "_-58L-V2mBkD"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "if(torch.cuda.is_available()):\n",
        "  train_loss_fn = nn.CrossEntropyLoss().cuda()\n",
        "  validate_loss_fn = nn.CrossEntropyLoss().cuda()\n",
        "else:\n",
        "  train_loss_fn = nn.CrossEntropyLoss()\n",
        "  validate_loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "WzsUAF5-CD5E"
      },
      "outputs": [],
      "source": [
        "# model_ema = ModelEma(\n",
        "#             model,\n",
        "#             decay=args.model_ema_decay,\n",
        "#             device='cpu' if args.model_ema_force_cpu else '',\n",
        "#             resume=args.resume)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "pjbUwPMXFeRt"
      },
      "outputs": [],
      "source": [
        "eval_metric = args.eval_metric\n",
        "best_metric = None\n",
        "best_epoch = None\n",
        "saver = None\n",
        "output_dir = results_main_path\n",
        "output_dir=''\n",
        "decreasing = True if eval_metric == 'loss' else False\n",
        "saver = CheckpointSaver(\n",
        "            model=model, optimizer=optimizer, args=args,\n",
        "            checkpoint_dir=output_dir, recovery_dir=output_dir, decreasing=decreasing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "YwgrQqPoJdeF"
      },
      "outputs": [],
      "source": [
        "def train_epoch(\n",
        "        epoch, model, loader, optimizer, loss_fn, args,\n",
        "        lr_scheduler=None, saver=None, output_dir='',\n",
        "        loss_scaler=None, model_ema=None, mixup_fn=None):\n",
        "  #print(\"came\")\n",
        "  model.train()\n",
        "  losses_m = AverageMeter()\n",
        "\n",
        "  second_order = hasattr(optimizer, 'is_second_order') and optimizer.is_second_order\n",
        "  num_updates = epoch * len(loader)\n",
        "  last_idx = len(loader) - 1\n",
        "  for batch_idx, (input, target) in enumerate(loader):\n",
        "    last_batch = batch_idx == last_idx\n",
        "    #print(last_batch)\n",
        "    if(torch.cuda.is_available()):\n",
        "      input, target = input.cuda(), target.cuda()\n",
        "\n",
        "    output = model(input)\n",
        "    input, target = input.cpu(), target.cpu()\n",
        "    output=output.cpu()\n",
        "\n",
        "    loss = loss_fn(output, target)\n",
        "    losses_m.update(loss.item(), input.size(0))\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward(create_graph=second_order)\n",
        "    optimizer.step()\n",
        "    lr_scheduler.step_update(num_updates=num_updates, metric=losses_m.avg)\n",
        "    if last_batch:\n",
        "      lrl = [param_group['lr'] for param_group in optimizer.param_groups]\n",
        "      lr = sum(lrl) / len(lrl)\n",
        "\n",
        "      print(\n",
        "                    'Train: {} [{:>4d}/{} ({:>3.0f}%)]  '\n",
        "                    'Loss: {loss.val:>9.6f} ({loss.avg:>6.4f})  '\n",
        "                    'LR: {lr:.3e}  '.format(\n",
        "                        epoch,\n",
        "                        batch_idx, len(loader),\n",
        "                        100. * batch_idx / last_idx,\n",
        "                        loss=losses_m,\n",
        "                        lr=lr))\n",
        "\n",
        "  return OrderedDict([('loss', losses_m.avg)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "n6Ri-CfUZGa4"
      },
      "outputs": [],
      "source": [
        "def validate(model, loader, loss_fn):\n",
        "\n",
        "    losses_m = AverageMeter()\n",
        "    top1_m = AverageMeter()\n",
        "    top5_m = AverageMeter()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    last_idx = len(loader) - 1\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (input, target) in enumerate(loader):\n",
        "            last_batch = batch_idx == last_idx\n",
        "            if(torch.cuda.is_available()):\n",
        "              input, target = input.cuda(), target.cuda()\n",
        "\n",
        "            output = model(input)\n",
        "\n",
        "            if isinstance(output, (tuple, list)):\n",
        "                output = output[0]\n",
        "\n",
        "            loss = loss_fn(output, target)\n",
        "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "\n",
        "            reduced_loss = loss.data\n",
        "\n",
        "            losses_m.update(reduced_loss.item(), input.size(0))\n",
        "            top1_m.update(acc1.item(), output.size(0))\n",
        "            top5_m.update(acc5.item(), output.size(0))\n",
        "\n",
        "            if last_batch:\n",
        "              print('Loss: {loss.val:>7.4f} ({loss.avg:>6.4f})  '\n",
        "                    'Acc@1: {top1.val:>7.4f} ({top1.avg:>7.4f})  '\n",
        "                    'Acc@5: {top5.val:>7.4f} ({top5.avg:>7.4f})'.format(\n",
        "                        loss=losses_m, top1=top1_m, top5=top5_m))\n",
        "\n",
        "    metrics = OrderedDict([('loss', losses_m.avg), ('top1', top1_m.avg), ('top5', top5_m.avg)])\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "kW4ZMWVtmBnA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "outputId": "0c198b4c-28d3-4b28-b219-178249c5d849"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0 [  84/85 (100%)]  Loss:  2.147064 (2.4297)  LR: 8.400e-03  \n",
            "Loss:  1.9011 (2.1855)  Acc@1:  0.0000 (15.2731)  Acc@5: 100.0000 (73.3556)\n",
            "Train: 1 [  84/85 (100%)]  Loss:  1.529758 (2.2632)  LR: 8.400e-03  \n",
            "Loss:  2.2310 (3.2590)  Acc@1:  0.0000 (16.0535)  Acc@5: 100.0000 (69.5652)\n",
            "Train: 2 [  84/85 (100%)]  Loss:  2.003206 (2.2813)  LR: 6.800e-03  \n",
            "Loss:  1.8128 (2.7816)  Acc@1:  0.0000 (15.2731)  Acc@5: 100.0000 (75.1394)\n",
            "Train: 3 [  84/85 (100%)]  Loss:  1.981048 (2.0617)  LR: 5.200e-03  \n",
            "Loss:  1.9699 (2.1504)  Acc@1:  0.0000 (14.6042)  Acc@5: 100.0000 (73.3556)\n",
            "Train: 4 [  84/85 (100%)]  Loss:  1.859122 (2.0124)  LR: 3.600e-03  \n",
            "Loss:  2.0731 (2.3054)  Acc@1:  0.0000 (15.4961)  Acc@5: 100.0000 (72.0178)\n",
            "Train: 5 [  84/85 (100%)]  Loss:  2.795616 (1.9893)  LR: 1.988e-03  \n",
            "Loss:  1.9760 (2.1479)  Acc@1:  0.0000 (15.9420)  Acc@5:  0.0000 (72.4638)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-158b27bf5538>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# if args.distributed:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#   loader_train.sampler.set_epoch(epoch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   train_metrics = train_epoch(epoch, model, trainLoader, optimizer, train_loss_fn, args,\n\u001b[0m\u001b[1;32m     10\u001b[0m                 lr_scheduler=lr_scheduler)\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-e9a09ea3f2a8>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(epoch, model, loader, optimizer, loss_fn, args, lr_scheduler, saver, output_dir, loss_scaler, model_ema, mixup_fn)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#print(last_batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m       \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_losses = []\n",
        "valid_losses = []\n",
        "top1_accuracies = []\n",
        "\n",
        "\n",
        "for epoch in range(0, num_epochs):\n",
        "    # if args.distributed:\n",
        "    #   loader_train.sampler.set_epoch(epoch)\n",
        "  train_metrics = train_epoch(epoch, model, trainLoader, optimizer, train_loss_fn, args,\n",
        "                lr_scheduler=lr_scheduler)\n",
        "\n",
        "  eval_metrics = validate(model, testLoader, validate_loss_fn)\n",
        "\n",
        "  train_losses.append(train_metrics['loss'])\n",
        "  valid_losses.append(eval_metrics['loss'])\n",
        "\n",
        "  top1_accuracies.append(eval_metrics['top1'])\n",
        "\n",
        "\n",
        "\n",
        "  lr_scheduler.step(epoch + 1, eval_metrics[eval_metric])\n",
        "  update_summary(\n",
        "                epoch, train_metrics, eval_metrics, os.path.join(output_dir, 'summary.csv'),\n",
        "                write_header=best_metric is None)\n",
        "\n",
        "\n",
        "                # save proper checkpoint with eval metric\n",
        "  save_metric = eval_metrics[eval_metric]\n",
        "  best_metric, best_epoch = saver.save_checkpoint(epoch, metric=save_metric)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftRRzx-Uv4Mm"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# files.download('./model_best.pth.tar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eixui0xo8OAE"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "num_epochs = num_epochs\n",
        "def loss_curves(epochs, training_epoch_loss,valid_epoch_loss):\n",
        "    plt.title('Mean Squared Error v Epochs', fontsize=20)\n",
        "    plt.xlabel('No. of Epochs', fontsize=18)\n",
        "    plt.ylabel('Mean Squared Error', fontsize=16)\n",
        "\n",
        "    plt.plot(epochs, training_epoch_loss,label=\"Training Loss\")\n",
        "    plt.plot(epochs, valid_epoch_loss,label=\"Validation Loss\")\n",
        "    plt.legend()\n",
        "#     plt.savefig('Model_3_128_AFLw_Test_ds.jpg')\n",
        "\n",
        "def accuracy_curves(epochs, val_accuracy):\n",
        "    plt.title('Validation Accuracy v Epochs', fontsize=20)\n",
        "    plt.xlabel('No. of Epochs', fontsize=18)\n",
        "    plt.ylabel('Validation Accuracy', fontsize=16)\n",
        "\n",
        "    plt.plot(epochs, val_accuracy,label=\"Validation Accuracy\")\n",
        "\n",
        "    plt.legend()\n",
        "#     plt.savefig('Model_3_128_AFLw_Test_ds.jpg')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrLysRHoRJWA"
      },
      "outputs": [],
      "source": [
        "loss_curves(np.linspace(0, num_epochs, num_epochs).astype(int),train_losses,valid_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuE7lB6oRNwY"
      },
      "outputs": [],
      "source": [
        "accuracy_curves(np.linspace(0, num_epochs, num_epochs).astype(int),top1_accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1vhHnvSgSvg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auc4SNFF7keg"
      },
      "outputs": [],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxnN7iQyWQ32"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-_uAfV4npTr"
      },
      "outputs": [],
      "source": [
        "def testModel(model,loader,load_model_path):\n",
        "\n",
        "  #checkpoint = torch.load(load_model_path)\n",
        "  #model.load_state_dict(checkpoint['state_dict'])\n",
        "  #model.load_state_dict(checkpoint)\n",
        "  #optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "  model.eval()\n",
        "\n",
        "  # for batch_idx, (input, target) in enumerate(loader):\n",
        "  #   print(batch_idx)\n",
        "  #   if(torch.cuda.is_available()):\n",
        "  #     input, target = input.cuda(), target.cuda()\n",
        "\n",
        "  #   output = model(input)\n",
        "\n",
        "  #   if isinstance(output, (tuple, list)):\n",
        "  #     output = output[0]\n",
        "  #   print(output)\n",
        "\n",
        "  subset_indices = [700] # select your indices here as a list\n",
        "  subset = torch.utils.data.Subset(loader, subset_indices)\n",
        "  testloader_subset = torch.utils.data.DataLoader(subset, batch_size=1, num_workers=0, shuffle=False)\n",
        "\n",
        "  input, target = next(iter(testloader_subset))\n",
        "  plt.imshow(input[0].permute(1,2,0),interpolation='none')\n",
        "  plt.show()\n",
        "\n",
        "  if(torch.cuda.is_available()):\n",
        "    input, target = input.cuda(), target.cuda()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  output = model(input)\n",
        "\n",
        "  if isinstance(output, (tuple, list)):\n",
        "    output = output[0]\n",
        "  print(output)\n",
        "  print(\"Predicted label: \",torch.argmax(output).item())\n",
        "  print(\"Real Label: \",target.item())\n",
        "  print(loader.class_to_idx)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Mgra959b91N"
      },
      "outputs": [],
      "source": [
        "#load_model_path=os.path.join(data_path,\"2023-05-12\",\"model_saved.pt\")\n",
        "#load_model_path='./last.pth.tar'\n",
        "load_model_path=os.path.join(\"model_best.pth.tar\")\n",
        "\n",
        "checkpoint = torch.load(load_model_path)\n",
        "\n",
        "torch.save(model.state_dict(),os.path.join(results_main_path,\"model_saved.pt\"))\n",
        "#model.load_state_dict(checkpoint)\n",
        "model.load_state_dict(checkpoint['state_dict'])\n",
        "\n",
        "optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "model.eval()\n",
        "\n",
        "#testModel(model,dataSet,load_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHTMXQdgwima"
      },
      "outputs": [],
      "source": [
        "model.cpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zG54YhDNoEPX"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "# iterate over test data\n",
        "for input, target in testLoader:\n",
        "  # if(torch.cuda.is_available()):\n",
        "  #   input, target = input.cuda(), target.cuda()\n",
        "\n",
        "  output = model(input)\n",
        "\n",
        "\n",
        "  #print(output)\n",
        "  #output = torch.argmax(output).data.cpu().numpy()\n",
        "  #input.cpu()\n",
        "  output = (torch.max(output, 1)[1]).data.numpy()\n",
        "  y_pred.extend(output) # Save Prediction\n",
        "  #print(y_pred)\n",
        "  labels = target.data.cpu().numpy()\n",
        "\n",
        "  y_true.extend(labels) # Save Truth\n",
        "  #print(y_true)\n",
        "  #print(y_true)\n",
        "# constant for classes\n",
        "classes = ('Benign','Phishing')\n",
        "\n",
        "# Build confusion matrix\n",
        "cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "acc=accuracy_score(y_pred,y_true)\n",
        "print(acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyrXMnpU5ZHn"
      },
      "outputs": [],
      "source": [
        "\n",
        "df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index = [i for i in classes],\n",
        "                     columns = [i for i in classes])\n",
        "plt.figure(figsize = (12,7))\n",
        "sn.heatmap(df_cm, annot=True)\n",
        "plt.savefig('output.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wy5FYrrXA0If"
      },
      "outputs": [],
      "source": [
        "\n",
        "TN = cf_matrix[0][0]\n",
        "FN = cf_matrix[1][0]\n",
        "TP = cf_matrix[1][1]\n",
        "FP = cf_matrix[0][1]\n",
        "\n",
        "print(TN,FN,TP,FP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xYj4-lHr9dq"
      },
      "outputs": [],
      "source": [
        "\n",
        "plt.figure(figsize = (12,7))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OuSN2pisdrg"
      },
      "outputs": [],
      "source": [
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CplZK_FjPQ1"
      },
      "outputs": [],
      "source": [
        "plt.savefig('output.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feyyV5HWjVDS"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3GR3Bd0vnag"
      },
      "outputs": [],
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "def count_parameters(model):\n",
        "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
        "    total_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad: continue\n",
        "        param = parameter.numel()\n",
        "        table.add_row([name, param])\n",
        "        total_params+=param\n",
        "    print(table)\n",
        "    print(f\"Total Trainable Params: {total_params}\")\n",
        "    return total_params\n",
        "\n",
        "count_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-727m1ySFQYc"
      },
      "outputs": [],
      "source": [
        "pip install torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKeu56Q-FNwO"
      },
      "outputs": [],
      "source": [
        "from torch.utils.mobile_optimizer import optimize_for_mobile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlsmMcwLAt0Y"
      },
      "outputs": [],
      "source": [
        "example = torch.randn(64,3,224,224)\n",
        "\n",
        "traced_script_module = torch.jit.trace(model, example)\n",
        "\n",
        "\n",
        "traced_script_module_optimized = optimize_for_mobile(traced_script_module)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9oEvIx60UWpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traced_script_module.save(os.path.join(results_main_path,\"model_jit.pt\"))"
      ],
      "metadata": {
        "id": "eZSd_qZxTXp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "El9SewfUYY2n"
      },
      "outputs": [],
      "source": [
        "traced_script_module_optimized._save_for_lite_interpreter(os.path.join(results_main_path,\"model.ptl\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traced_script_module_optimized=torch.jit.load(os.path.join(results_main_path,\"model.ptl\"))"
      ],
      "metadata": {
        "id": "tCtvwKciUYEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "# iterate over test data\n",
        "for input, target in testLoader:\n",
        "  # if(torch.cuda.is_available()):\n",
        "  #   input, target = input.cuda(), target.cuda()\n",
        "\n",
        "  output = traced_script_module_optimized(input)\n",
        "\n",
        "\n",
        "  #print(output)\n",
        "  #output = torch.argmax(output).data.cpu().numpy()\n",
        "  #input.cpu()\n",
        "  output = (torch.max(output, 1)[1]).data.numpy()\n",
        "  y_pred.extend(output) # Save Prediction\n",
        "  #print(y_pred)\n",
        "  labels = target.data.cpu().numpy()\n",
        "\n",
        "  y_true.extend(labels) # Save Truth\n",
        "  #print(y_true)\n",
        "  #print(y_true)\n",
        "# constant for classes\n",
        "classes = ('Benign','Phishing')\n",
        "\n",
        "# Build confusion matrix\n",
        "cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "acc=accuracy_score(y_pred,y_true)\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "YUyX0tvTiuxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def testModel(model,loader,load_model_path,indice):\n",
        "\n",
        "  #checkpoint = torch.load(load_model_path)\n",
        "  #model.load_state_dict(checkpoint['state_dict'])\n",
        "  #model.load_state_dict(checkpoint)\n",
        "  #optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "  #model.eval()\n",
        "\n",
        "  # for batch_idx, (input, target) in enumerate(loader):\n",
        "  #   print(batch_idx)\n",
        "  #   if(torch.cuda.is_available()):\n",
        "  #     input, target = input.cuda(), target.cuda()\n",
        "\n",
        "  #   output = model(input)\n",
        "\n",
        "  #   if isinstance(output, (tuple, list)):\n",
        "  #     output = output[0]\n",
        "  #   print(output)\n",
        "\n",
        "  subset_indices = [indice] # select your indices here as a list\n",
        "  subset = torch.utils.data.Subset(loader, subset_indices)\n",
        "  testloader_subset = torch.utils.data.DataLoader(subset, batch_size=1, num_workers=0, shuffle=False)\n",
        "\n",
        "  input, target = next(iter(testloader_subset))\n",
        "  plt.imshow(input[0].permute(1,2,0),interpolation='none')\n",
        "  plt.show()\n",
        "\n",
        "  # if(torch.cuda.is_available()):\n",
        "  #   input, target = input.cuda(), target.cuda()\n",
        "\n",
        "\n",
        "\n",
        "  print(type(input))\n",
        "  output = model(input)\n",
        "\n",
        "  if isinstance(output, (tuple, list)):\n",
        "    output = output[0]\n",
        "  print(output)\n",
        "  print(\"Predicted label: \",torch.argmax(output).item())\n",
        "  print(\"Real Label: \",target.item())\n",
        "  print(loader.class_to_idx)"
      ],
      "metadata": {
        "id": "vNDOIoFnFom6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testModel(traced_script_module_optimized,dataSet,load_model_path,2000)"
      ],
      "metadata": {
        "id": "YqPS5HEuHbSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "from torchvision import transforms\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "WUgW8t96H0rT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path=\"benign_test\"\n",
        "name='00000.PNG'"
      ],
      "metadata": {
        "id": "LkFTIVUzXuxj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}